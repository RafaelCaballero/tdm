{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Una introducción a Spark con Python\n",
    "\n",
    "#### Rafael Caballero\n",
    "\n",
    "Casi todo el código extraído del libro *Big Data con Python*\n",
    "\n",
    "## 0: Preparación\n",
    "\n",
    "\n",
    "#### Windows\n",
    "\n",
    "El mismo código debería funcionar en otros sistemas \n",
    "\n",
    "* \n",
    "* Instrucciones para linux: https://blog.sicara.com/get-started-pyspark-jupyter-guide-tutorial-ae2fe84f594f\n",
    "* Instrucciones para windows: https://medium.com/@ashish1512/how-to-setup-apache-spark-pyspark-on-jupyter-ipython-notebook-3330543ab307\n",
    "\n",
    "En el laboratorio tenemos el problema de que no podemos hacer nuestras propias instalaciones; por ello podemos copiar la carpeta spark hlocal\\tdm y ejecutar el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# copiar la carpeta spark en c:\\hlocal\\tdm\n",
    "import os\n",
    "# cambiamos las variables del sistema\n",
    "spark = 'C:\\\\hlocal\\\\tdm\\\\spark\\\\hadoop\\\\spark-2.3.2-bin-hadoop2.7'\n",
    "# en el path se añade\n",
    "path = os.environ.get('PATH') \n",
    "path = path+ ';'+spark+'\\\\bin;'\n",
    "os.environ['PATH'] = path\n",
    "os.environ['SPARK_HOME']= spark \n",
    "os.environ['HADOOP_HOME']= spark \n",
    "os.environ['PYSPARK_DRIVER_PYTHON']= 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='notebook'\n",
    "\n",
    "# si da problema con collect quizás haya que poner java_home\n",
    "os.environ['JAVA_HOME']= 'C:\\\\JDK\\\\jdk8-64bits'\n",
    "os.environ['PATH'] = os.environ.get('JAVA_HOME')+'\\\\bin;'+path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "| hola|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "df = spark.sql('''select 'spark' as hola ''')\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Acciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al importar pyspark ya tenemos una variable spark con la conexión con Spark creada. Para manejar RDDs nos interesará extraer de ella el llamado *sparkContext*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "r = sc.parallelize([1,2,3]) # Crea un RDD con los valores 1,2,3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el tipo de la variable r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9, 16]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuadrados = sc.parallelize([i*i for i in range(100)])\n",
    "l = cuadrados.take(5)\n",
    "l[2:]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones  collect, take y count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las *acciones* son las que lanzan un cómputo.\n",
    "** collect ** recupera todo un RDD como si se tratara de un array\n",
    "\n",
    "*Ojo*: Si hacemos esto nos traemos toda la colección al ordenador en el que estamos, ¡eso no es big data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 25,\n",
       " 36,\n",
       " 49,\n",
       " 64,\n",
       " 81,\n",
       " 100,\n",
       " 121,\n",
       " 144,\n",
       " 169,\n",
       " 196,\n",
       " 225,\n",
       " 256,\n",
       " 289,\n",
       " 324,\n",
       " 361,\n",
       " 400,\n",
       " 441,\n",
       " 484,\n",
       " 529,\n",
       " 576,\n",
       " 625,\n",
       " 676,\n",
       " 729,\n",
       " 784,\n",
       " 841,\n",
       " 900,\n",
       " 961,\n",
       " 1024,\n",
       " 1089,\n",
       " 1156,\n",
       " 1225,\n",
       " 1296,\n",
       " 1369,\n",
       " 1444,\n",
       " 1521,\n",
       " 1600,\n",
       " 1681,\n",
       " 1764,\n",
       " 1849,\n",
       " 1936,\n",
       " 2025,\n",
       " 2116,\n",
       " 2209,\n",
       " 2304,\n",
       " 2401,\n",
       " 2500,\n",
       " 2601,\n",
       " 2704,\n",
       " 2809,\n",
       " 2916,\n",
       " 3025,\n",
       " 3136,\n",
       " 3249,\n",
       " 3364,\n",
       " 3481,\n",
       " 3600,\n",
       " 3721,\n",
       " 3844,\n",
       " 3969,\n",
       " 4096,\n",
       " 4225,\n",
       " 4356,\n",
       " 4489,\n",
       " 4624,\n",
       " 4761,\n",
       " 4900,\n",
       " 5041,\n",
       " 5184,\n",
       " 5329,\n",
       " 5476,\n",
       " 5625,\n",
       " 5776,\n",
       " 5929,\n",
       " 6084,\n",
       " 6241,\n",
       " 6400,\n",
       " 6561,\n",
       " 6724,\n",
       " 6889,\n",
       " 7056,\n",
       " 7225,\n",
       " 7396,\n",
       " 7569,\n",
       " 7744,\n",
       " 7921,\n",
       " 8100,\n",
       " 8281,\n",
       " 8464,\n",
       " 8649,\n",
       " 8836,\n",
       " 9025,\n",
       " 9216,\n",
       " 9409,\n",
       " 9604,\n",
       " 9801]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = sc.parallelize([i*i for i in range(100)])\n",
    "r.collect()  # Falla en algunas versiones de Java!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es mucho más normal recuperar solo unos cuantos elementos. De esto se encarga *take(n)* que devuelve los n primeros miembros del rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "print(r.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, *count* nos dice de cuántos elementos consta un RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = sc.textFile('C:/hlocal/tdm/quijote.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37861\n",
      "['The Project Gutenberg EBook of Don Quijote, by Miguel de Cervantes Saavedra', '', 'This eBook is for the use of anyone anywhere at no cost and with', 'almost no restrictions whatsoever.  You may copy it, give it away or', 're-use it under the terms of the Project Gutenberg License included', 'with this eBook or online at www.gutenberg.net', '', '', 'Title: Don Quijote', '']\n"
     ]
    }
   ],
   "source": [
    "print(texto.count())\n",
    "print(texto.take(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce, fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*reduce* es una de las operaciones claves en Spark. \n",
    "Reduce todos los elementos de un RDD a uno solo. \n",
    "Para ello toma una función que aplica:\n",
    "    * Primero a los dos primeros elementos, dando un resultado r1\n",
    "    * Luego a r1 y al tercer elemento, dando r2\n",
    "    * ... así hasta rn-1 y el último elemento, que dan el valor final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2\n",
      "3 3\n",
      "6 4\n",
      "10 5\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "def add(x,y):\n",
    "    print(x,y)\n",
    "    return x+y\n",
    "\n",
    "r = sc.parallelize(range(1,6))\n",
    "print(r.reduce(add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# Otra forma de lograr lo mismo: funciones lambda\n",
    "print(r.reduce(lambda x,y: x+y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fold() es similar a reduce, excepto porque toma un 'valor cero' inicial, al que podemos llamar z. \n",
    "Dado un valor z y una lista l, la función se aplica\n",
    "    * Primero a z y al primer elemento de l, dando un resultado r1\n",
    "    * Luego a r1 y al segundo elemento de l, dando r2\n",
    "    * ... así hasta rn-1 y el último elemento, que dan el valor final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r.fold(0,lambda x,y: x+y)) #raro!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map\n",
    "\n",
    "Aplica una función a todos los miembros de un RDD. La salida es otro RDD con tantos elementos como tenía la entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[75, 0, 64, 68, 67]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def longitud(s):\n",
    "    return len(s)\n",
    "longitudes = texto.map(longitud)\n",
    "print(longitudes.count())\n",
    "longitudes.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('THE', 3),\n",
       " ('PROJECT', 7),\n",
       " ('GUTENBERG', 9),\n",
       " ('EBOOK', 5),\n",
       " ('OF', 2),\n",
       " ('DON', 3),\n",
       " ('QUIJOTE,', 8),\n",
       " ('BY', 2),\n",
       " ('MIGUEL', 6),\n",
       " ('DE', 2),\n",
       " ('CERVANTES', 9),\n",
       " ('SAAVEDRA', 8),\n",
       " ('', 0),\n",
       " ('THIS', 4),\n",
       " ('EBOOK', 5),\n",
       " ('IS', 2),\n",
       " ('FOR', 3),\n",
       " ('THE', 3),\n",
       " ('USE', 3),\n",
       " ('OF', 2)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def divide(s):\n",
    "    return s.split(\" \")\n",
    "##################################\n",
    "texto\\\n",
    ".flatMap(divide)\\\n",
    ".map(lambda s:s.upper())\\\n",
    ".map(lambda s : (s,len(s)))\\\n",
    ".take(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter\n",
    "\n",
    "Aplica una función booleana a todos los miembros de un RDD. La salida es otro RDD que solo tiene los miembros para los que la función devuelve True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 14,\n",
       " 16,\n",
       " 18,\n",
       " 20,\n",
       " 22,\n",
       " 24,\n",
       " 26,\n",
       " 28,\n",
       " 30,\n",
       " 32,\n",
       " 34,\n",
       " 36,\n",
       " 38,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 46,\n",
       " 48]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeros = sc.parallelize(range(50))\n",
    "numeros.filter(lambda n: (n%2) == 0).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo complejo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('QUE', 19470)\n"
     ]
    }
   ],
   "source": [
    "def maxpareja(s1,s2):\n",
    "    if s1[1]>s2[1]:\n",
    "        r = s1\n",
    "    else:\n",
    "        r = s2\n",
    "    return r\n",
    "pareja = texto.flatMap(lambda line: line.split(\" \")) \\\n",
    "             .map(lambda s:s.upper())\\\n",
    "             .map(lambda word: (word, 1)) \\\n",
    "             .reduceByKey(lambda a, b: a + b)\\\n",
    "             .reduce(maxpareja)\n",
    "        \n",
    "print(pareja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "leer el quijote en un RDD y cuente el número de frases que contienen el texto 'merced'.\n",
    "Nota: no importa que la palabra venga dentro de otra palabra, se contará igual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
