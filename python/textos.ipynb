{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z-0iMEoyigc"
      },
      "source": [
        "# Análisis de textos\n",
        "\n",
        "Empezamos instalando una biblioteca que vamos a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AcLCGST7yaxF"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "bibliotecas = [\"spacytextblob\",\"flair\",\"goose3\",\"wordcloud\"]\n",
        "\n",
        "import sys\n",
        "import os.path\n",
        "from subprocess import check_call\n",
        "import importlib\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "def instala_bibliotecas(bibliotecas):\n",
        "  print(\"Instalando bibliotecas\")\n",
        "  alguna = False\n",
        "  for m in bibliotecas:\n",
        "      # para el import quitamos [...] y ==...\n",
        "      p = m.find(\"[\")\n",
        "      mi = m if p==-1 else m[:p]\n",
        "      p = mi.find(\"==\")\n",
        "      mi = mi if p==-1 else mi[:p]\n",
        "\n",
        "      torch_loader = importlib.util.find_spec(mi)\n",
        "      if torch_loader is not None:\n",
        "          print(m, \" encontrado\")\n",
        "      else:\n",
        "          print(m, \" No encontrado, instalando...\",end=\"\")\n",
        "          try:\n",
        "            r = check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--user\", m])\n",
        "            print(\"¡Hecho!\")\n",
        "            alguna = True\n",
        "          except:\n",
        "            print(\"¡Problema al instalar \",m,\"! ¿seguro que el módulo existe?\",sep=\"\")\n",
        "\n",
        "  print(\"¡Terminado!\")\n",
        "  if alguna:\n",
        "    print(\"Recuerda reiniciar (Entorno de ejecución + Reiniciar entorno de ejecución) para que la(s) nueva(s) biblioteca(s) estén disponbles\")\n",
        "\n",
        "pipelines = ['en_core_web_sm']\n",
        "#pipelines = [\"en_core_web_lg\"]\n",
        "def instala_pipelines(pipelines):\n",
        "  print(\"Instalando pipelines de Spacy\")\n",
        "  for p in pipelines:\n",
        "      print(\"Instalando \",p)\n",
        "      try:\n",
        "        r = check_call([sys.executable, \"-m\", \"spacy\", \"download\", p])\n",
        "        print(\"¡Hecho!\")\n",
        "      except:\n",
        "        print(\"¡Problema al instalar \",p,\"! ¿seguro que el pipeline existe?\",sep=\"\")\n",
        "\n",
        "  print(\"¡Terminado!\")\n",
        "\n",
        "instala_pipelines(pipelines)\n",
        "\n",
        "instala_bibliotecas(bibliotecas)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxxHXpOKhZ17"
      },
      "outputs": [],
      "source": [
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9zhAa7FAidN"
      },
      "source": [
        "### ¿De dónde salen los datos?\n",
        "\n",
        "\n",
        "\n",
        "*   Programación con bibliotecas\n",
        "*   [Programas especializados](https://chrome.google.com/webstore/detail/aliexpress-reviews-export/glnajkhggmbljlcafknlkcihcheoankc?hl=en)\n",
        "* Bases de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aPG8ntZ8bnv"
      },
      "outputs": [],
      "source": [
        "# origen https://www.amazon.com/-/es/product-reviews/B07ZPKF8RG/ref=cm_cr_unknown?ie=UTF8&filterByStar=two_star&reviewerType=all_reviews&pageNumber=1#reviews-filter-bar\n",
        "textos = ['Broken. It was supposed to be a B-Day gift for my mom and now she doesn’t get a gift on her Bday',\n",
        "          'Touchscreen became almost completely unresponsive over 20% of surface area within days',\n",
        "          \"A little over 90 days, hardware failure, NO Solution, DON'T BUY\",\n",
        "          \"Wanted to love it, but it had too many problems upon arrival\",\n",
        "          \"Phone is great but the battery health is 76%\",\n",
        "          \"Happy customer! It came with protective glass installed.\",\n",
        "          \"Great phone for the price!\",\n",
        "          \"I love this phone\",\n",
        "          \"Definitely Recommend!\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBIJqw81I9NQ"
      },
      "source": [
        "Librería Spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmKkD31-yWhG"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "nlp.add_pipe('spacytextblob')\n",
        "\n",
        "for text in textos:\n",
        "    print(text)\n",
        "    doc = nlp(text) # esto devuelve datos sobre el \"sentimiento\" del texto\n",
        "    print(doc._.blob.polarity)\n",
        "    print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzeQecGrJBb5"
      },
      "source": [
        "Librería Flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcOY76Z_vzfK"
      },
      "outputs": [],
      "source": [
        "from flair.models import TextClassifier\n",
        "from flair.data import Sentence\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "\n",
        "for s in textos:\n",
        "  text = Sentence(s)\n",
        "\n",
        "  classifier.predict(text)\n",
        "  value = text.labels[0].to_dict()\n",
        "  print(s)\n",
        "  print(value)\n",
        "  print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para jugar"
      ],
      "metadata": {
        "id": "YvFlHExajY5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Wonderful room, beautiful views\"\n",
        "text = Sentence(s)\n",
        "classifier = TextClassifier.load('en-sentiment')\n",
        "classifier.predict(text)\n",
        "value = text.labels[0].to_dict()\n",
        "print(value)"
      ],
      "metadata": {
        "id": "XCw7OUSRjaW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRwnZiGnDIOI"
      },
      "source": [
        "¿Cuál es mejor?  Vamos a utilizar una base de datos de opiniones de películas ya etiquetadas y ver cúal acierta más"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hI4EVPEDSWf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"https://github.com/RafaelCaballero/tdm/blob/master/datos/IMDB10K.zip?raw=true\",compression='zip')\n",
        "total = 250\n",
        "df = df.sample(250)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gvw_MYIJLBx"
      },
      "source": [
        "SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGL-8GGzEPwn"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "spacyOp = []\n",
        "for text in tqdm(df.review):\n",
        "  doc = nlp(text)\n",
        "  polaridad = doc._.blob.polarity\n",
        "  spacyOp.append(0 if polaridad<0 else +1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mGayOsAJgRB"
      },
      "source": [
        "Flair"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkOknlWCEuL4"
      },
      "outputs": [],
      "source": [
        "flairOp = []\n",
        "for s in tqdm(df.review):\n",
        "    text = Sentence(s)\n",
        "    classifier.predict(text)\n",
        "    value = text.labels[0].to_dict()[\"value\"]\n",
        "    flairOp.append(+1 if value==\"POSITIVE\" else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xPJMhouJlcJ"
      },
      "source": [
        "Comparamos con el sentimiento \"real\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSWctnHJGBhw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def show_cm(y_real,y_pred):\n",
        "    labels = list(set(y_real))\n",
        "    cf_matrix = confusion_matrix(y_real, y_pred, labels=labels)\n",
        "    ax = sns.heatmap(cf_matrix/sum(cf_matrix), annot=True, fmt='.2', cmap='Blues')\n",
        "y_real = [+1 if v==\"positive\" else 0 for v in df.sentiment]\n",
        "\n",
        "print(\"Spacy\")\n",
        "show_cm(y_real, spacyOp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "relMjzX4Ir76"
      },
      "outputs": [],
      "source": [
        "print(\"Flair\")\n",
        "show_cm(y_real, flairOp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLab36CONei0"
      },
      "source": [
        "Curiosidades...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPhVl087NhO5"
      },
      "outputs": [],
      "source": [
        "frase = \"jew\"\n",
        "\n",
        "import spacy\n",
        "from spacytextblob.spacytextblob import SpacyTextBlob\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "nlp.add_pipe('spacytextblob')\n",
        "\n",
        "print(\"SpaCy\")\n",
        "doc = nlp(frase)\n",
        "print(\"Polaridad: \",doc._.blob.polarity)\n",
        "print(\"=\"*30)\n",
        "\n",
        "print(\"Flair\")\n",
        "text = Sentence(frase)\n",
        "classifier.predict(text)\n",
        "value = text.labels[0].to_dict()\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7P7yZdOOl6J"
      },
      "source": [
        "## NER (Named Entity Recognition)\n",
        "\n",
        "Reconocimiento de sustantivos que denotan nombres, organizaciones, etc. Importante para saber de qué se está hablando en textos complejos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vg8XVJsQZl8"
      },
      "outputs": [],
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "\n",
        "# load tagger\n",
        "tagger = SequenceTagger.load(\"flair/ner-spanish-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdfPFENHOjvK"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# make example sentence\n",
        "sentence = Sentence(\"George Washington fue a Washington, mientras que mi amiga Belén visitaba Belén\")\n",
        "\n",
        "# predict NER tags\n",
        "tagger.predict(sentence)\n",
        "\n",
        "# print sentence\n",
        "print(sentence)\n",
        "\n",
        "# print predicted NER spans\n",
        "print('The following NER tags are found:')\n",
        "# iterate over entities and print\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpM0WsNXQl2j"
      },
      "outputs": [],
      "source": [
        "s = \"\"\"\n",
        "Hermoso y clásico apartamento a cuadras de la Plaza Mayor\n",
        "10\n",
        "Liked · Lindo apartamento. Cómodo y espacioso. Muy bien ubicado. Javier fue muy amable en todo. Pasamos una muy grata estancia como familia.\n",
        "Disliked · La señal Wifi tenía bajo rango, desconectandose cada cierto tiempo\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "sentence = Sentence(s)\n",
        "\n",
        "# predict NER tags\n",
        "tagger.predict(sentence)\n",
        "\n",
        "\n",
        "# print predicted NER spans\n",
        "print('The following NER tags are found:')\n",
        "# iterate over entities and print\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ct1TWRo2SGAs"
      },
      "source": [
        "## Frases y palabras\n",
        "\n",
        "Una de las tareas más comunes al tratar con textos largos es separar en frases y mostrar las palabras más frecuentes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylGlbFQQSLwy"
      },
      "outputs": [],
      "source": [
        "from goose3 import Goose\n",
        "#import es_core_news_sm\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# descargamos la noticia\n",
        "g = Goose()\n",
        "pag_dir = \"https://elpais.com/espana/2023-02-23/espana-sufre-hoy-el-dia-mas-duro-del-nuevo-episodio-invernal-con-11-comunidades-en-alerta-por-nevadas-a-cotas-muy-bajas.html\"\n",
        "articulo = g.extract(url=pag_dir)\n",
        "texto = articulo.cleaned_text\n",
        "# utilizamos el modelo para contar oraciones\n",
        "#nlp = es_core_news_sm.load()\n",
        "doc = nlp(texto)\n",
        "print(\"El artículo incluye \", len(list(doc.sents)),\"oraciones\")\n",
        "for i,s in enumerate(doc.sents):\n",
        "  print(i,s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYHq-7PgV4xE"
      },
      "source": [
        "Nos preguntamos qué palabras aparecen más en el texto. Una primera versión con no demasiado éxito"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcgsFA0BWBKc"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "palabras = texto.split(\" \")\n",
        "c2 = Counter(palabras)\n",
        "print(c2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypMBU0ARWOBT"
      },
      "source": [
        "No resulta muy útil debido a la abundancia de las palabras vacías o \"stop words\". Veamos cómo quitarlas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfkvHAODWUNb"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "nlp = spacy.load('es_core_news_md')\n",
        "\n",
        "doc = nlp(texto)\n",
        "palabras = [p.text.upper() for p in doc\n",
        "             if p.is_alpha and not p.is_stop]\n",
        "frecuencia = Counter(palabras)\n",
        "palabras_comunes = frecuencia.most_common(5)\n",
        "print(palabras_comunes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bLhVQnnTjec"
      },
      "source": [
        "## Nubes de palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKs62linTnxj"
      },
      "outputs": [],
      "source": [
        "from goose3 import Goose\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# descargamos la noticia\n",
        "g = Goose()\n",
        "pag_dir = \"https://elpais.com/diario/1980/12/10/cultura/345250806_850215.html\"\n",
        "#pag_dir = \"https://elpais.com/espana/2023-02-23/espana-sufre-hoy-el-dia-mas-duro-del-nuevo-episodio-invernal-con-11-comunidades-en-alerta-por-nevadas-a-cotas-muy-bajas.html\"\n",
        "\n",
        "articulo = g.extract(url=pag_dir)\n",
        "texto = articulo.cleaned_text\n",
        "\n",
        "# generar nube de palabras\n",
        "nlp = spacy.blank('es')\n",
        "palabrasvacías = nlp.Defaults.stop_words\n",
        "#palabrasvacías.add(\"zona\")\n",
        "w  = WordCloud(stopwords = palabrasvacías)\n",
        "w.generate(texto)\n",
        "\n",
        "# mostramos el resultado\n",
        "fig, ax = plt.subplots(1,1, figsize=(20,7),dpi=100)\n",
        "plt.imshow(w)\n",
        "fig.savefig(\"wordcloud1.png\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}