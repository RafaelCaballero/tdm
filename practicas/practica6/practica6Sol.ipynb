{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 6\n",
    "### TDM - Máster en IoT - Rafael Caballero\n",
    "\n",
    "Vamos a trabajar con datos de las evaluaciones Pisa por páises para tres disciplinas: ciencias (SCI), lectura (REA) y matemáticas (MAT). Los datos se han obtenido de: https://www.kaggle.com/zazueta/pisa-scores-2015\n",
    "\n",
    "Por favor, empezad poniendo el nombre:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nombre: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparado!!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "# cambiamos las variables del sistema\n",
    "spark = 'C:\\\\hlocal\\\\tdm\\\\spark\\\\hadoop\\\\spark-2.3.2-bin-hadoop2.7'\n",
    "# en el path se añade\n",
    "path = os.environ.get('PATH') \n",
    "path = path+ ';'+spark+'\\\\bin;'\n",
    "os.environ['PATH'] = path\n",
    "os.environ['SPARK_HOME']= spark \n",
    "os.environ['HADOOP_HOME']= spark \n",
    "os.environ['PYSPARK_DRIVER_PYTHON']= 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='notebook'\n",
    "\n",
    "# si da problema con collect quizás haya que poner java_home\n",
    "os.environ['JAVA_HOME']= 'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_151'\n",
    "#labs = 'C:\\\\JDK\\\\jdk8-64bits'\n",
    "#os.environ['JAVA_HOME']= labs\n",
    "os.environ['PATH'] = os.environ.get('JAVA_HOME')+'\\\\bin;'+path\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print(\"Preparado!!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos\n",
    "*1.* Cargar el fichero 'PisaData.csv', que contiene los resultados en las pruebas Pisa por países para los años 2013,2014,2015. \n",
    "Inicialmente lo cargamos como un RDD de texto, al que llamaremos raw_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CountryName,CountryCode,Series Name,Code,YR2013,YR2014,YR2015',\n",
       " 'Albania,ALB,PISA: Mean performance on the mathematics scale,LO.PISA.MAT,..,..,413.157',\n",
       " 'Albania,ALB,PISA: Mean performance on the mathematics scale. Female,LO.PISA.MAT.FE,..,..,417.750029482799',\n",
       " 'Albania,ALB,PISA: Mean performance on the mathematics scale. Male,LO.PISA.MAT.MA,..,..,408.545458736189',\n",
       " 'Albania,ALB,PISA: Mean performance on the reading scale,LO.PISA.REA,..,..,405.2588']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#path = 'c:\\\\hlocal\\\\tdm\\\\PisaData.csv'\n",
    "path = 'c:\\\\hlocal\\\\tdm\\\\PisaData.csv' # cambiar si está en otro lugarç\n",
    "\n",
    "raw_data = sc.textFile(path).cache() # Un RDD de strings\n",
    "raw_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento\n",
    "\n",
    "Vemos algunas valores tienen '..' en lugar de un valor numérico. Se tratan de datos *missing*, es decir no conocidos, para algún año, asignatura y país. El problema de estos datos es que impedirían inferir que los campos son de tipo numérico.  Como en todo caso solo nos interesa el año 2015, lo primero que vamos a hacer es quedarnos con las columnas que nos interesan, y luego descartar, si los hay, los valores missing. Lo hacemos por fases\n",
    "\n",
    "*2*  Utilizar una operación adecuado sobre RDDs que convierta el RDD en uno de arrays de strings, donde cada componente del array es un campo. Para ellos se debe separar cada línea por el carácter , (ver notebook SparkSQL). El resultado se llamara csv_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['CountryName',\n",
       "  'CountryCode',\n",
       "  'Series Name',\n",
       "  'Code',\n",
       "  'YR2013',\n",
       "  'YR2014',\n",
       "  'YR2015'],\n",
       " ['Albania',\n",
       "  'ALB',\n",
       "  'PISA: Mean performance on the mathematics scale',\n",
       "  'LO.PISA.MAT',\n",
       "  '..',\n",
       "  '..',\n",
       "  '413.157'],\n",
       " ['Albania',\n",
       "  'ALB',\n",
       "  'PISA: Mean performance on the mathematics scale. Female',\n",
       "  'LO.PISA.MAT.FE',\n",
       "  '..',\n",
       "  '..',\n",
       "  '417.750029482799'],\n",
       " ['Albania',\n",
       "  'ALB',\n",
       "  'PISA: Mean performance on the mathematics scale. Male',\n",
       "  'LO.PISA.MAT.MA',\n",
       "  '..',\n",
       "  '..',\n",
       "  '408.545458736189'],\n",
       " ['Albania',\n",
       "  'ALB',\n",
       "  'PISA: Mean performance on the reading scale',\n",
       "  'LO.PISA.REA',\n",
       "  '..',\n",
       "  '..',\n",
       "  '405.2588']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# solución\n",
    "csv_data = raw_data.map(lambda l: l.split(\",\")) \n",
    "\n",
    "# para probar\n",
    "csv_data.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3** Solo nos interesan las columnas que ocupan las posiciones 0 (CountryName), 3 (Code) y 6 (YR2015). \n",
    "Escribir la operación sobre RDDs que crea a partir de csv_data un nuevo RDD, al que llamaremos datosRDD, que solo tiene estas columnas\n",
    "\n",
    "Pista: Dada una fila l, queremos consutruir un nuevo array con los valores l[0],l[3] y l[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['CountryName', 'Code', 'YR2015'],\n",
       " ['Albania', 'LO.PISA.MAT', '413.157'],\n",
       " ['Albania', 'LO.PISA.MAT.FE', '417.750029482799'],\n",
       " ['Albania', 'LO.PISA.MAT.MA', '408.545458736189'],\n",
       " ['Albania', 'LO.PISA.REA', '405.2588']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datosRDD = csv_data.map(lambda l: [l[0],l[3],l[6]])\n",
    "\n",
    "# Para probar\n",
    "print(datosRDD.count()) # los mismos que csv_data:1167\n",
    "datosRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4** Ahora quitamos los valores missing para la columna de índice 2. Es decir, quitamos aquellas filas cuyo valor en la columna 2 sea '..'.\n",
    "El nuevo RDD se llamará *datosRDD2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['CountryName', 'Code', 'YR2015'],\n",
       " ['Albania', 'LO.PISA.MAT', '413.157'],\n",
       " ['Albania', 'LO.PISA.MAT.FE', '417.750029482799'],\n",
       " ['Albania', 'LO.PISA.MAT.MA', '408.545458736189'],\n",
       " ['Albania', 'LO.PISA.REA', '405.2588'],\n",
       " ['Albania', 'LO.PISA.REA.FE', '434.639625546737'],\n",
       " ['Albania', 'LO.PISA.REA.MA', '375.75919916958'],\n",
       " ['Albania', 'LO.PISA.SCI', '427.225'],\n",
       " ['Albania', 'LO.PISA.SCI.FE', '439.442962901842'],\n",
       " ['Albania', 'LO.PISA.SCI.MA', '414.957643727778'],\n",
       " ['Algeria', 'LO.PISA.MAT', '359.6062']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4\n",
    "datosRDD2 = datosRDD.filter(lambda l: l[2]!='..')\n",
    "print(datosRDD2.count()) # Quedan 582\n",
    "datosRDD2.take(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# este código se encarga de trasponer los datos anteriores de forma que cada país \\n# aparezca una sola vez y tenga 10 columnas asociadas, una por medida\\nfrom itertools import islice\\n\\n# quitamos la primera fila\\nsinHeader = datosRDD2.mapPartitionsWithIndex(\\n    lambda idx, it: islice(it, 1, None) if idx == 0 else it \\n)\\n# convertimos cada uno en parejas\\nparejas = sinHeader.map(lambda l: (l[0],[l[2]]))\\nprint(parejas.take(5))\\npaises = parejas.reduceByKey(lambda a,b:[a[0]+','+b[0]]).map(lambda a:a[0]+','+a[1][0])\\npaises.take(5)\\nprint(paises.count())\\n\\nopath= 'c:\\\\hlocal\\\\tdm\\\\PisaData2.csv'\\npaises.saveAsTextFile(opath)\\n# nota, habría que añadir las cabeceras\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignorar, solo como curiosidad.\n",
    "'''\n",
    "# este código se encarga de trasponer los datos anteriores de forma que cada país \n",
    "# aparezca una sola vez y tenga 10 columnas asociadas, una por medida\n",
    "from itertools import islice\n",
    "\n",
    "# quitamos la primera fila\n",
    "sinHeader = datosRDD2.mapPartitionsWithIndex(\n",
    "    lambda idx, it: islice(it, 1, None) if idx == 0 else it \n",
    ")\n",
    "# convertimos cada uno en parejas\n",
    "parejas = sinHeader.map(lambda l: (l[0],[l[2]]))\n",
    "print(parejas.take(5))\n",
    "paises = parejas.reduceByKey(lambda a,b:[a[0]+','+b[0]]).map(lambda a:a[0]+','+a[1][0])\n",
    "paises.take(5)\n",
    "print(paises.count())\n",
    "\n",
    "opath= 'c:\\\\hlocal\\\\tdm\\\\PisaData2.csv'\n",
    "paises.saveAsTextFile(opath)\n",
    "# nota, habría que añadir las cabeceras\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carga de datos (2)\n",
    "\n",
    "**5.** Cargar el fichero 'PisaDataBis.csv', que contiene los resultados en las pruebas Pisa por países para 2015. Utilizar el método 'fácil' que permite leer todo el fichero como una dataframe, infiriendo el esquema. Llamar al dataframe 'datos_df'\n",
    "\n",
    "Nota: El fichero contiene cabeceras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "root\n",
      " |-- PAIS: string (nullable = true)\n",
      " |-- MAT: double (nullable = true)\n",
      " |-- MAT_FE: double (nullable = true)\n",
      " |-- MAT_MA: double (nullable = true)\n",
      " |-- REA: double (nullable = true)\n",
      " |-- REA_FE: double (nullable = true)\n",
      " |-- REA_MA: double (nullable = true)\n",
      " |-- SCI: double (nullable = true)\n",
      " |-- SCI_FE: double (nullable = true)\n",
      " |-- SCI_MA: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(PAIS='Albania', MAT=413.157, MAT_FE=417.750029482799, MAT_MA=408.545458736189, REA=405.2588, REA_FE=434.639625546737, REA_MA=375.75919916958, SCI=427.225, SCI_FE=439.442962901842, SCI_MA=414.957643727778),\n",
       " Row(PAIS='Algeria', MAT=359.6062, MAT_FE=363.072479076874, MAT_MA=356.495105666181, REA=349.8593, REA_FE=366.208166798086, REA_MA=335.185435908668, SCI=375.7451, SCI_FE=383.220938935314, SCI_MA=369.035233788056),\n",
       " Row(PAIS='Argentina', MAT=409.0333, MAT_FE=400.443116055612, MAT_MA=418.388360865522, REA=425.3031, REA_FE=432.95807959441, REA_MA=416.966607209736, SCI=432.2262, SCI_FE=424.994351346692, SCI_MA=440.102029698007),\n",
       " Row(PAIS='Australia', MAT=493.8962, MAT_FE=490.985500770373, MAT_MA=496.761344887127, REA=502.9006, REA_FE=518.865799240277, REA_MA=487.18552546683, SCI=509.9939, SCI_FE=508.921647404582, SCI_MA=511.049257232073),\n",
       " Row(PAIS='Austria', MAT=496.7423, MAT_FE=483.133026052429, MAT_MA=510.098215924204, REA=484.8656, REA_FE=495.075191103096, REA_MA=474.846031609294, SCI=495.0375, SCI_FE=485.526754333789, SCI_MA=504.371197291877)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = 'c:\\\\hlocal\\\\tdm\\\\PisaDataBis.csv'\n",
    "# Cambiar si el path es diferente\n",
    "path = 'c:\\\\hlocal\\\\tdm\\\\PisaDataBis.csv'\n",
    "\n",
    "# solucion; debe crear un dataframe datos\n",
    "datos_df = spark.read.format(\"com.databricks.spark.csv\")\\\n",
    "            .options(header='true', inferschema='true') \\\n",
    "            .load(path)\n",
    "\n",
    "print(datos_df.count()) # 64\n",
    "datos_df.printSchema()\n",
    "datos_df.take(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas básicas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6** Dibujar el histograma correspondiente a la columna 'SCI' que da los datos globales en ciencias. Usar un gráfico de 23 barras en azul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17a785e9668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from pyspark_dist_explore import hist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "col = 'SCI'\n",
    "hist(ax, datos_df.select([col]), bins = 23, color=['blue'])\n",
    "plt.xlabel(col)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7** Observamos algo curioso: la gráfica parece tener varios 'picos' (¿varias normales superpuestas?). \n",
    "    Escribir una instrucción en SPARKSQL que nos devuelva un dataframe los países que están por debajo de 450. \n",
    "    El nuevo dataframe recibirá como nombre menor_df. \n",
    "    \n",
    "    Utilizar una instrucción filter de SPARK SQL, seguida de un select para tomar solo la columna país\n",
    "    \n",
    "    https://stackoverflow.com/questions/45978108/multiple-condition-filter-on-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# solución\n",
    "menor_df = datos_df.filter('SCI < 440').select(['PAIS','SCI'])\n",
    "\n",
    "# quitar comentario para probar\n",
    "#menor_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **8** Número de países en los que las mujeres son peores en lectura que los hombres (REA_FE < REA_MA)\n",
    " \n",
    " Ayuda: El resultado es ¡0!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_df.filter('REA_FE < REA_MA').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Vemos que corresponden a países con renta per capita no muy alta. Digamos que el histograma muestra las diferencias en renta\n",
    "\n",
    "**9**  ¿Es la correlación entre SCI (columna 7 de datos_df) y MAT (columna 1) es mayor que la correlación entre SCI y REA (columna 4)?. Mostrar ambos valores. Ayuda: Ver SparkSQL, justo antes de 'muestras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corr. sci-mat:  Row(corr(SCI, MAT)=0.9744212449079869)  corr. sci-rea:  Row(corr(SCI, REA)=0.9625212644401843)\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import corr\n",
    "import math \n",
    "\n",
    "sci = 7\n",
    "mat = 1\n",
    "rea = 4\n",
    "\n",
    "sci_mat = datos_df.select(corr(datos_df.columns[sci], datos_df.columns[mat])).first()\n",
    "sci_rea = datos_df.select(corr(datos_df.columns[sci], datos_df.columns[rea])).first()\n",
    "\n",
    "print(\"corr. sci-mat: \",sci_mat,' corr. sci-rea: ',sci_rea)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10** Queremos saber qué decil ocupa españa en ciencias (SCI). Para ello\n",
    "\n",
    "1. Obtendremos el valor de españa en ciencias\n",
    "2. Calcularemos los deciles de la columna sci con la función approxQuantile (sobre la que debemos buscar información en internet). Usar como cota del error el valor 0.\n",
    "3. Mostraremos el decil por pantalla (D1 si está en el mejor 10%, D2 si está en el top 20%, y así hasta D10 si está en el peor 10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D4\n"
     ]
    }
   ],
   "source": [
    "# solución\n",
    "\n",
    "# dato de españa\n",
    "spa = datos_df.filter(\"PAIS='Spain'\").select(['SCI']).first()[0]\n",
    "\n",
    "# deciles\n",
    "quantiles = datos_df.approxQuantile(\"SCI\", [ i*0.1 for i in range(1,10) ], 0) \n",
    "\n",
    "# buscar hueco\n",
    "i=0\n",
    "while i<=8 and quantiles[i]<spa:\n",
    "    i+=1\n",
    "print('D'+str(10-i))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
