{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Práctica 8\n",
    "### Tratamiento de datos masivos\n",
    "\n",
    "Partimos del fichero p8data.csv que tiene los datos obtenidos a partir de los sensores del móvil en el bolsillo de personas que han hecho distintos ejercicios, además de algunos datos personales.\n",
    "\n",
    "*0 -> subir escaleras\n",
    "\n",
    "*1 -> bajarlas\n",
    "\n",
    "*2 -> sentarse\n",
    "\n",
    "*3 -> ponerse de pie\n",
    "\n",
    "*4 -> andar \n",
    "\n",
    "*5 -> correr\n",
    "\n",
    "El objetivo de esta práctica es intentar predecir el tipo de movimiento. Para ello se pide elaborar un modelo clasificador que sea capaz de predecir la etiqueta (el tipo de movimiento). \n",
    "\n",
    "Se juzgará el resultado atendiendo al menor valor F-score obtenido de los F-scores asociados a cada categoría.\n",
    "\n",
    "![imagen.png](https://wikimedia.org/api/rest_v1/media/math/render/svg/057ffc6b4fa80dc1c0e1f2f1f6b598c38cdd7c23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "# cambiamos las variables del sistema\n",
    "spark = 'C:\\\\hlocal\\\\tdm\\\\spark\\\\hadoop\\\\spark-2.3.2-bin-hadoop2.7'\n",
    "# en el path se añade\n",
    "path = os.environ.get('PATH') \n",
    "path = path+ ';'+spark+'\\\\bin;'\n",
    "os.environ['PATH'] = path\n",
    "os.environ['SPARK_HOME']= spark \n",
    "os.environ['HADOOP_HOME']= spark \n",
    "os.environ['PYSPARK_DRIVER_PYTHON']= 'jupyter'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='notebook'\n",
    "\n",
    "# si da problema con collect quizás haya que poner java_home\n",
    "#os.environ['JAVA_HOME']= 'C:\\\\Program Files\\\\Java\\\\jdk1.8.0_151'\n",
    "labs = 'C:\\\\JDK\\\\jdk8-64bits'\n",
    "os.environ['JAVA_HOME']= labs\n",
    "os.environ['PATH'] = os.environ.get('JAVA_HOME')+'\\\\bin;'+path\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "print(\"Preparado!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solución\n",
    "\n",
    "#debe quear en una variable modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# esto para grabar \n",
    "#path = 'c:/hlocal/tdm/modelo'\n",
    "path = 'c:/hlocal/tdm/modelo'\n",
    "model.write.save(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
